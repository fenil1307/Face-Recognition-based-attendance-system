import cv2
import os
import numpy as np
import face_recognition
from datetime import datetime

#creat empty list and make a list of those data which we will use as photo name
path='image'
image=[]
personname=[]
mylist=os.listdir(path)
print(mylist)

for cu_img in mylist:
    current_img=cv2.imread(f'{path}/{cu_img}')
    image.append(current_img)
    personname.append(os.path.splitext(cu_img)[0])
print(personname)

def faceEncoding(image):
    encodelist=[]
    for img in image:
        img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)
        encode=face_recognition.face_encodings(img)[0]
        encodelist.append(encode)
    return encodelist




-----------------------------------------------------------------------------------------------------------------------
import cv2
import csv
from cvzone.HandTrackingModule import HandDetector
import cvzone
import time

cap = cv2.VideoCapture(0)
cap.set(3, 1280)
cap.set(4, 720)
detector = HandDetector(detectionCon=0.8)


class MCQ():
    def __init__(self, data):
        self.Question = data[0]
        self.Choice1 = data[1]
        self.Choice2 = data[2]
        self.Choice3 = data[3]
        self.Choice4 = data[4]
        self.Answer = int(data[5])

        self.userAns = None

    def update(self, cursor, bboxs):

        for x, bbox in enumerate(bboxs):
            x1, y1, x2, y2 = bbox
            if x1 < cursor[0] < x2 and y1 < cursor[1] < y2:
                self.userAns = x + 1
                cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), cv2.FILLED)


# Import csv file data
pathCSV = "mcqq.csv"
with open(pathCSV, newline='\n') as f:
    reader = csv.reader(f)
    dataAll = list(reader)[1:]

# Create Object for each MCQ
mcqList = []
for q in dataAll:
    mcqList.append(MCQ(q))

print("Total MCQ Objects Created:", len(mcqList))

qNo = 0
qTotal = len(dataAll)

while True:
    success, img = cap.read()
    img = cv2.flip(img, 1)
    hands, img = detector.findHands(img, flipType=False)

    if qNo < qTotal:
        mcq = mcqList[qNo]

        img, bbox = cvzone.putTextRect(img, mcq.Question, [100, 100], 2, 2, offset=50, border=5)
        img, bbox1 = cvzone.putTextRect(img, mcq.Choice1, [100, 250], 2, 2, offset=50, border=5)
        img, bbox2 = cvzone.putTextRect(img, mcq.Choice2, [400, 250], 2, 2, offset=50, border=5)
        img, bbox3 = cvzone.putTextRect(img, mcq.Choice3, [100, 400], 2, 2, offset=50, border=5)
        img, bbox4 = cvzone.putTextRect(img, mcq.Choice4, [400, 400], 2, 2, offset=50, border=5)

        if hands:
            lmList = hands[0]['lmList']
            cursor = lmList[8]
            length, info = detector.findDistance(lmList[8], lmList[12])
            print(length)
            if length < 35:
                mcq.update(cursor, [bbox1, bbox2, bbox3, bbox4])
                if mcq.userAns is not None:
                    time.sleep(0.3)
                    qNo += 1
    else:
        score = 0
        for mcq in mcqList:
            if mcq.Answer == mcq.userAns:
                score += 1
        score = round((score / qTotal) * 100, 2)
        img, _ = cvzone.putTextRect(img, "Quiz Completed", [250, 300], 2, 2, offset=50, border=5)
        img, _ = cvzone.putTextRect(img, f'Your Score: {score}%', [700, 300], 2, 2, offset=50, border=5)

    # Draw Progress Bar
    barValue = 150 + (950 // qTotal) * qNo
    cv2.rectangle(img, (150, 600), (barValue, 650), (0, 255, 0), cv2.FILLED)
    cv2.rectangle(img, (150, 600), (1100, 650), (255, 0, 255), 5)
    img, _ = cvzone.putTextRect(img, f'{round((qNo / qTotal) * 100)}%', [1130, 635], 2, 2, offset=16)

    cv2.imshow("Img", img)
    cv2.waitKey(1)




encodelistknown=faceEncoding(image)
print("ALL ENCODING DONE!!!!")


def attendance(name):
    with open("at.csv", 'r+') as f:

        mydatalist=f.readlines()
        namelist=[]
        for line in mydatalist:
            entry=line.split(',')
            namelist.append(entry[0])
        if name not in namelist:
            time_now=datetime.now()
            tstr=time_now.strftime('%H:%M:%S')
            dstr=time_now.strftime('%d/%m/%Y')
            f.writelines(f'{name},{tstr},{dstr}\n')

cap = cv2.VideoCapture(0)

while(True):
    ret, frame=cap.read()
    faces=cv2.resize(frame,(0,0),None,1,1)
    faces=cv2.cvtColor(faces,cv2.COLOR_BGR2RGB)
    facescurrentframe=face_recognition.face_locations(faces)
    encodesCurrentFrame=face_recognition.face_encodings(faces, facescurrentframe)

    for encodeface, faceloc in zip(encodesCurrentFrame, facescurrentframe):
        match=face_recognition.compare_faces(encodelistknown, encodeface)
        facedis=face_recognition.face_distance(encodelistknown, encodeface)
        matchindex=np.argmin(facedis)
        if match[matchindex]:
            name=personname[matchindex].upper()

            y1,x2,y2,x1=faceloc

            cv2.rectangle(frame,(x1,y1),(x2,y2),(0,255,0),2)
            cv2.rectangle(frame, (x1,y2-35),(x2,y2),(0,255,0),cv2.FILLED)
            cv2.putText(frame, name, (x1+6,y2-6),cv2.FONT_HERSHEY_PLAIN,1,(0,0,255),2)
            attendance(name)
    cv2.imshow("camera",frame)
    if cv2.waitKey(10)==13:
        break
cap.release()
cv2.destroyAllWindows()



